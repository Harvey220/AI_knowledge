# 术语

![image-20251201203118671](./images/image-20251201203118671.png)

# 推荐系统概览

<img src="./images/image-20251201203358970.png" alt="image-20251201203358970" style="zoom:67%;" />

![image-20251201203423077](./images/image-20251201203423077.png)

# 候选集的生成

![image-20251201204751092](./images/image-20251201204751092.png)

## 基于内容的过滤

![image-20251201210241232](./images/image-20251201210241232.png)

**基于内容的过滤（Content-based Filtering）** 是一种推荐系统方法，根据用户的历史偏好或项目的内容特征进行个性化推荐。

**优势：**

- **无需其他用户数据**：推荐是特定于用户的，因此模型不需要其他用户的行为数据，便于扩展到大量用户。
- **捕捉用户兴趣**：能够精准捕捉用户的兴趣，推荐一些**小众物品**，即使这些物品的其他用户兴趣较少。

**缺点：**

- **依赖手工特征**：由于物品的特征需要手动设计，因此需要大量领域知识。模型的效果取决于这些特征的质量。
- **局限于已有兴趣**：模型只能基于用户现有的兴趣进行推荐，扩展用户兴趣的能力有限。

基于内容的推荐系统适用于需要精准匹配用户兴趣的场景，但也存在一定的局限性，特别是在发现用户潜在兴趣方面。

## 协同过滤 

**协同过滤**是通过分析用户与物品之间的交互数据（如评分、点击等）来为用户推荐物品。它不依赖物品的内容特征，而是基于用户行为或物品相似性进行推荐。

- **基于用户的协同过滤：**通过查找与目标用户兴趣相似的其他用户来推荐物品。

- **基于物品的协同过滤：**通过查找与目标物品相似的其他物品来进行推荐。

### **矩阵因式分解模型与公式**

协同过滤的核心是基于用户和物品的**反馈矩阵**，通过**矩阵因式分解**来降低维度并捕捉用户与物品之间的潜在关系。

#### 1. **反馈矩阵 A**

假设有 m 个用户和 n 个物品，反馈矩阵 A 是一个 m×n 的矩阵，其中 $A_{ij}$ 表示用户 i 对物品 j 的反馈（例如评分）。
$$
A = \begin{pmatrix} A_{11} & A_{12} & \cdots & A_{1n} \\ A_{21} & A_{22} & \cdots & A_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ A_{m1} & A_{m2} & \cdots & A_{mn} \end{pmatrix}
$$

#### 2. **矩阵因式分解**

协同过滤通过矩阵因式分解将 A 分解成两个低维矩阵 U 和 V，其中：

- U 是 m×d 的用户嵌入矩阵，表示用户的潜在特征。
- V 是 n×d 的物品嵌入矩阵，表示物品的潜在特征。
- d 是嵌入的维度，通常远小于 m 和 n。

目标是通过点积（点积可以捕捉到相似性）使得矩阵因式分解的结果尽可能接近原始矩阵 A：
$$
A_{ij} \approx U_i \cdot V_j^T
$$
其中：

- $U_i$ 是用户 i 的嵌入向量（一个 d 维向量），
- $V_j$ 是物品 j 的嵌入向量（一个 d 维向量），
- $U_i \cdot V_j^T$ 是用户 i 对物品 j 的预测评分。

------

### 目标函数：最小化误差

训练的目标是最小化预测评分 $\hat{A}_{ij} = U_i \cdot V_j$ 与真实评分 $A_{ij}$ 之间的误差。最常见的目标函数是**平方误差**（MSE）：
$$
\text{Loss} = \sum_{(i,j) \in \text{observed}} (A_{ij} - \hat{A}_{ij})^2
$$
这里，$(i,j)∈observed(i,j) $ 表示我们只对已观察到的条目求和，忽略那些未观察到的条目。

#### **加权矩阵分解**

为了处理未观察条目的问题（例如冷启动问题），我们通常使用加权矩阵分解，其中每个条目 $A_{ij}$ 会乘上一个权重 $w_{ij}$，使得模型可以在优化过程中给予不同条目不同的权重：
$$
\text{Loss} = \sum_{(i,j) \in \text{observed}} w_{ij} \cdot (A_{ij} - U_i \cdot V_j^T)^2
$$
其中 $w_{ij}$ 是一个超参数，用于控制每个条目的权重。例如，频繁的物品可以给予较低的权重，稀有物品则给予较高的权重。

------

### **优化算法**

#### 1. **随机梯度下降法 (SGD)**

- **目标**：通过计算目标函数的梯度来更新用户和物品的嵌入向量 $U_i$ 和 $V_j$。

- **公式**：更新嵌入向量的步骤是通过梯度下降计算：
  $$
  U_i \leftarrow U_i - \eta \frac{\partial \text{Loss}}{\partial U_i}, \quad V_j \leftarrow V_j - \eta \frac{\partial \text{Loss}}{\partial V_j}
  $$
  其中，$\eta$ 是学习率。

#### 2. **加权交替最小二乘法 (WALS)**

- **目标**：通过交替优化 $U_i$ 和 $V_j$ 来最小化损失。每次固定一个矩阵，优化另一个矩阵。

- **过程**：

  - **第一步**：固定物品嵌入矩阵 V，解决用户嵌入矩阵 U 的问题。
  - **第二步**：固定用户嵌入矩阵 U，解决物品嵌入矩阵 V 的问题。

  WALS 通过精确求解线性方程来更新嵌入矩阵，每步都能精确减少损失，因此收敛较快。

------

### 总结

- **协同过滤**依赖于用户和物品之间的交互数据，通过矩阵因式分解来优化用户和物品的嵌入向量，从而进行推荐。
- **目标函数**使用平方误差来衡量预测评分和实际评分之间的差距，训练过程中优化这些嵌入向量。
- 常用的优化算法包括**SGD**（灵活但收敛慢）和**WALS**（收敛快，特别适合矩阵因式分解）。

矩阵因式分解是推荐系统的核心方法之一，能够帮助我们有效地捕捉用户与物品之间的隐式关系。







































