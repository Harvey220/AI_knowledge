# 线性回归

## 线性回归的常见损失函数

![image-20251127171644002](./images/image-20251127171644002.png)

## 凸函数

![image-20251127173652053](./images/image-20251127173652053.png)

## 常见超参数

![image-20251127174449308](./images/image-20251127174449308.png)

### **对于学习率大小的选择权衡**

- 如果学习速率过小，则可能需要过多的迭代次数才能实现收敛
- 过大的学习速率永远不会收敛，因为每次迭代都会导致损失在较大范围内波动或持续增加
- 理想的学习率有助于模型在合理的迭代次数内收敛

### **批次大小**

数据集包含数十万甚至数百万个示例，所以在更新模型的权重和偏差时，使用完整批次数据并不实际。以下两种常见技术可在不查看数据集中的每个示例的情况下，获得正确的*平均*梯度，然后更新权重和偏差：

- **随机梯度下降法 (SGD)**：随机梯度下降法在每次迭代中仅使用一个示例（批次大小为 1）。使用随机梯度下降可能会在整个损失曲线中产生噪声，而不仅仅是在接近收敛时。
- **小批次随机梯度下降法（小批次 SGD）**：小批次随机梯度下降法是全批次和 SGD 之间的折衷方案。确定每个批次的样本数量取决于数据集和可用的计算资源。



# 逻辑回归

## 逻辑函数

![image-20251127201153872](./images/image-20251127201153872.png)

## 对数损失

![image-20251127201714891](./images/image-20251127201714891.png)

## 逻辑回归中的正则化

![image-20251127201952821](./images/image-20251127201952821.png)

![image-20251127203741155](./images/image-20251127203741155.png)

### **为什么逻辑回归在大量特征且无正则化时，损失会趋近于 0？**

（1）逻辑回归的损失函数是负对数似然（NLL），对“正确且自信的预测”奖励过度，对“过度自信”没有惩罚。

（2）在高维特征空间中，数据更容易线性可分，一旦可分，模型可以无限增大权重的模长，使预测概率越来越接近 1 或 0。

（3）当权重持续变大时，正例的$W^Tx \to +\infty$，负例的$W^Tx \to -\infty$，从而使 NLL 中的 $−log⁡p$ 或 $−log⁡(1−p)$ 趋近于 0。

（4）因此，在无正则化的情况下，梯度下降不会停止，损失会持续下降，而参数的模长会无限发散。



# 分类

## 混淆矩阵

![image-20251127210038084](./images/image-20251127210038084.png)

## 准确率、召回率、精确率和相关指标

![image-20251127211056240](./images/image-20251127211056240.png)



![image-20251127211142663](./images/image-20251127211142663.png)

![image-20251127211451496](./images/image-20251127211451496.png)![image-20251127211545143](./images/image-20251127211545143.png)

![image-20251127212131209](./images/image-20251127212131209.png)

## 接收器操作特征曲线 (ROC)和曲线下面积(AUC)

![image-20251127213445983](./images/image-20251127213445983.png)

![image-20251127213808471](./images/image-20251127213808471.png)

![image-20251127213958446](./images/image-20251127213958446.png)

# 数据

## 处理数值数据

### 初始步骤

检查数据数据的两种方式：

- 在图表或图形中直观呈现数据。
- 获取有关数据的统计信息。

#### 统计数值数据

一般，使用pandas库的describe方法来显示统计指标，包括：

- `count` 是此列中填充元素的数量。理想情况下，每个列的 `count` 值都相同，但这并非总是如此。
- `mean` 是该列中值的传统平均值。我们建议将每个列的 `mean` 与中位数进行比较。**中位数**是表格的 50% 行。
- `std` 是此列中值的标准差。
- `min`、`25%`、`50%`、`75%` 和 `max` 表示 0、25、50、75 和 100 百分位数的值。

根据统计指标可以发现离群值：

1. **标准差（`std`）与平均值（`mean`）的比较：** 如果一个列的标准差非常大，甚至接近或超过其平均值，这表明数据分布非常分散，可能存在一些极端值（离群值）将数据向一侧拉伸。
2. 四分位数与最大值/最小值的比较：
   - **最大值（`max`）与 75% 分位数之间的巨大差异：** 这表示有少数值远大于数据集中绝大多数的其他值。例如，如果 75% 的数据都在某个相对较小的范围内，但最大值却异常庞大，这通常是离群值的迹象。
   - **最小值（`min`）与 25% 分位数之间的巨大差异（反向）：** 类似地，如果最小值远小于 25% 分位数，也可能存在异常小的离群值。

### 数值数据的标准化/归一化

#### 线性缩放

![image-20251128140414378](./images/image-20251128140414378.png)

![image-20251128140426686](./images/image-20251128140426686.png)

#### Z-score缩放

![image-20251128140752455](./images/image-20251128140752455.png)

![image-20251128140840480](./images/image-20251128140840480.png)

![image-20251128140925339](./images/image-20251128140925339.png)

#### 对数缩放

![image-20251128141116717](./images/image-20251128141116717.png)

一个直观的理解：取对数，可以把数值较小的范围的分布拉大，把数值较大的范围的分布拉小

<img src="./images/image-20251128142046683.png" alt="image-20251128142046683" style="zoom:67%;" />

#### 裁剪

![image-20251128142212166](./images/image-20251128142212166.png)

![image-20251128142221786](./images/image-20251128142221786.png)

<img src="./images/image-20251128142232754.png" alt="image-20251128142232754" style="zoom:67%;" />

![image-20251128142316407](./images/image-20251128142316407.png)

#### 归一化总结

![image-20251128142402857](./images/image-20251128142402857.png)

### 分箱

![image-20251128144431166](./images/image-20251128144431166.png)

![image-20251128144509506](./images/image-20251128144509506.png)

<img src="./images/image-20251128144523452.png" alt="image-20251128144523452" style="zoom:67%;" />

### 多项式转换

![image-20251128145533333](./images/image-20251128145533333.png)

### 总结

![image-20251128145809983](./images/image-20251128145809983.png)

## 处理分类数据

### 编码的概念

**编码**是指将分类数据或其他数据转换为**数值向量**可用于训练的模型。必须进行这种转换，因为模型仅使用浮点值进行训练；模型无法基于字符串进行训练， `"dog"` 或 `"maple"`。

![image-20251128151612812](./images/image-20251128151612812.png)

![image-20251128151633528](./images/image-20251128151633528.png)

**稀疏表示法：**如果某个特征的值主要为零（或为空），则该特征称为稀疏特征。许多分类特征（例如 `car_color`）往往是稀疏特征。稀疏表示形式为该特征的在向量里的索引，稀疏表示法占用的内存远少于八元素独热向量。重要的是，模型必须使用 one-hot 向量进行*训练*，而不是使用稀疏表示形式。**主要是存储的时候省内存！**

![image-20251128152235187](./images/image-20251128152235187.png)

# 数据集、泛化和过拟合

## 类别不平衡的数据集

### 类平衡数据集与类不平衡数据集有何区别？

在类别平衡的数据集中，正类别和负类别的数量大致相等。例如，一个包含 235 个正类和 247 个负类的数据集就被认为是平衡数据集。相反，在类别不平衡的数据集中，一个标签比另一个标签常见得多。在现实世界中，类别不平衡的数据集远比类别平衡的数据集常见。例如，在信用卡交易数据集中，欺诈性购买行为可能仅占样本的不到 0.1%。同样，在医疗诊断数据集中，患有某种罕见病毒的患者数量可能不到总样本数的 0.01%。在类别不平衡的数据集中，较常见的标签称为**多数类**，而较不常见的标签称为**少数类**.

### 为什么训练不平衡的数据集很困难？

训练旨在创建一个能够成功区分正类别和负类别的模型。为了实现这一目标，批次（batches）需要包含足够数量的正类别和负类别样本。当数据集的类别严重不平衡时，即使是较大的批次也可能无法包含足够的少数类示例来支持适当的训练。例如，如果一个数据集包含 200 个多数类标签和 2 个少数类标签，当批次大小为 20 时，大多数批次将不包含任何少数类别的样本。即使批次大小为 100，每个批次平均也只包含一个少数类示例，这不足以进行适当的训练。这种极度不平衡的比例会导致模型无法正常训练。

### 如何克服训练不平衡数据集的问题？

![image-20251128155709672](./images/image-20251128155709672.png)

## 过拟合

### 什么会导致过拟合？

一般来说，过拟合是由以下一种或两种问题导致的：

- 训练集不能充分代表真实数据（或验证集或测试集）。
- 模型过于复杂。

## 模型复杂性

机器学习模型必须同时满足两个相互冲突的目标：

- 能很好地拟合数据。
- 尽可能简单地拟合数据。

为了让模型保持简单，一种方法是惩罚复杂的模型；也就是说，在训练过程中强制模型变得更简单。对复杂模型进行惩罚是一种**正则化**。

![image-20251128161519658](./images/image-20251128161519658.png)



学到了L2正则化







