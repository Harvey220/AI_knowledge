![image-20251201202625855](./images/image-20251201202625855.png)

![image-20251201202715690](./images/image-20251201202715690.png)

![image-20251201202725625](./images/image-20251201202725625.png)

一般先训练几轮判别器，再训练生成器。

为什么用判别器而不用损失函数？ 为了更好地把握全局的信息。

当生成的结果无法被判别较好判断，那么这个GAN已经到头了。

GAN是半监督，不需要特别多的数据。

**梯度消失：**

> GAN 是一个对抗过程，如果判别器在训练初期迅速变得很强，它会把假样本判得非常自信，这会让生成器接收到的梯度非常小，导致生成器无法继续学习，也就是梯度消失。

**模式崩溃：**

> 生成器会集中生成能骗过判别器的那一类样本，而不是学习完整的真实分布；因为 GAN 的损失函数没有“覆盖所有模式”的约束，所以容易出现只生成单一类别的模式崩溃。

**对抗样本与对抗学习：**

对抗样本是通过沿着模型梯度方向加入极小扰动，使模型输出发生显著改变的输入，揭示了深度网络在输入空间上的不稳定性。

对抗学习通过把这些“最容易攻击模型的样本”加入训练集，让模型在训练过程中主动对抗这些扰动，相当于“最坏情况优化”，从而提升模型的鲁棒性。





















